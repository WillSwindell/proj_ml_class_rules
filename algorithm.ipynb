{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule Learner algorithm (PRISM)\n",
    "\n",
    "Use lecture slides and/or book chapters to understand the PRISM algorithm. \n",
    "\n",
    "Then implement the algorithm in this notebook. Implement it step-by-step, add explanations of every step, keep the code clean and modular. Finally, test the correctness of your algorithm on the contact lenses [dataset](contact_lenses.csv) discussed in class, to see if it produces the same rules.\n",
    "\n",
    "If the PRISM algorithm is designed to cover the entire dataset, then the rules can be organized into a decision table, and used for classification. However, in this project, we are more interested in extracting small nuggets of knowledge: the most reliable rules - with significant coverage and high accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Notes and suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Advice: work on the  algorithm implementation in IDE (such as Pycharm). This will allow you easily find and fix bugs. \n",
    "- After your algorithm works, you can copy it to this notebook in pieces and explain each part.\n",
    "- Use `pandas` and `numpy` whenever possible to make the program faster.\n",
    "- Use list comprehensions instead of loops - these run 10 times faster than native Python loops.\n",
    "- __Important:__ you do not have to use the starter logic below. You can delete all of this and write your own code from scratch. The goal was to help you, not to constrain your creativity to my way of thinking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithm implementation\n",
    "\n",
    "First, we need a datastructure to store each rule. \n",
    "Possible implementation of required data types is given below. You are free to either reuse them or create your own.\n",
    "\n",
    "Each Rule consists of antecedent (Left Hand Side) and consequent (Right Hand Side). The LHS includes multiple conditions joined with AND, and RHS is a class label. The Rule also needs to store its accuracy and coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rule:\n",
    "    def __init__(self, class_label):\n",
    "        self.conditions = []  # list of conditions\n",
    "        self.class_label = class_label  # rule class\n",
    "\n",
    "    def add_condition(self, condition):\n",
    "        self.conditions.append(condition)\n",
    "\n",
    "    def set_params(self, accuracy, coverage):\n",
    "        self.accuracy = accuracy\n",
    "        self.coverage = coverage\n",
    "    \n",
    "    # Human-readable printing of this Rule\n",
    "    def __repr__(self):\n",
    "        return \"If {} then {}. Coverage:{}, accuracy: {}\".format(self.conditions, self.class_label,\n",
    "                                                                 self.coverage, self.accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of conditions contains several objects of class Condition. \n",
    "\n",
    "Each condition includes the _attribute name_ and the _value_. \n",
    "\n",
    "If the _value_ is numeric, then the condition also includes an additional field `true_false` which means the following: *if true_false == True then values are >= value* and  *if true_false == False then values are < value*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Condition:\n",
    "    def __init__(self, attribute, value, true_false = None):\n",
    "        self.attribute = attribute\n",
    "        self.value = value\n",
    "        self.true_false = true_false\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.true_false is None:\n",
    "            return \"{}={}\".format(self.attribute, self.value)\n",
    "        else:\n",
    "            return \"{}>={}:{}\".format(self.attribute, self.value, self.true_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next comes the `learn_one_rule` algorithm. The required parameters are the names of the columns, the current subset of data, and the class label (RHS of this rule). The optional parameters are thresholds `min_coverage` and `min_accuracy`. \n",
    "\n",
    "In addition, sometimes we can pass an already existing Rule in order to learn a more refined condition. Now, if the Rule can be improved, we will return the new rule and the subset of data covered by the Rule. If we could not improve it - we return the original Rule and the original covered subset (`prev_covered`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_one_rule(columns, data, class_label, \n",
    "                   prev_rule=None, min_coverage=30,\n",
    "                   min_accuracy=0.6, prev_covered=None):\n",
    "    current_subset = data.copy()\n",
    "\n",
    "    current_rule = prev_rule\n",
    "    current_accuracy = 0\n",
    "    current_coverage = None\n",
    "    covered_subset = None\n",
    "    \n",
    "    if current_rule is not None:\n",
    "        current_accuracy = current_rule.accuracy\n",
    "        current_coverage = current_rule.coverage\n",
    "        covered_subset = prev_covered.copy()\n",
    "    \n",
    "    best_col = None\n",
    "    best_val = None\n",
    "    true_false = None\n",
    "\n",
    "    # find the rule with the highest accuracy by checking different possible conditions\n",
    "    for col in columns[:-1]:\n",
    "        # Extract unique values from the column\n",
    "        unique_vals = current_subset[col].unique().tolist()\n",
    "        \n",
    "        # Consider each unique value in turn\n",
    "        for val in unique_vals:\n",
    "            \n",
    "            # The treatment is different for numeric and categorical attributes\n",
    "            if isinstance(val, int) or isinstance(val, float):\n",
    "                # Here we construct 2 conditions: \n",
    "                # if actual value >= val and if actual value < val\n",
    "                \n",
    "                # Compute:\n",
    "                # total of >= val\n",
    "                # correct_total of >= val that have class_label\n",
    "                # total of < val\n",
    "                # correct_total of < val that have class_label\n",
    "               \n",
    "                \n",
    "                # If any of the correct_total >= min_coverage\n",
    "                # we compare their accuracy and choose the one with with higher accuracy\n",
    "                # in case of accuracy ties we choose the one with greater coverage\n",
    "                                \n",
    "                # Now we see if the best accuracy is above threshold \n",
    "                # and is better than the previous accuracy (rule improved)\n",
    "                # and remember this condition\n",
    "              \n",
    "            else:\n",
    "                # For categorical attributes - this is just a single condition: if actual value == val\n",
    "                total = len(current_subset[current_subset[col] == val])\n",
    "                # total of == val\n",
    "                # correct_total of == val that have class_label\n",
    "\n",
    "                # compute accuracy and coverage as before\n",
    "\n",
    "            # print(best_col, best_val, current_accuracy, current_coverage)\n",
    "\n",
    "    # If we managed to improve the rule accuracy\n",
    "    if best_col is not None:\n",
    "        # If the rule does not exist - create it\n",
    "        if current_rule is None:\n",
    "            current_rule = Rule(class_label)\n",
    "        # Create a condition based on best_col, best_val and true_false\n",
    "        condition = Condition(best_col, best_val, true_false)\n",
    "        current_rule.add_condition(condition)\n",
    "        current_rule.set_params(current_accuracy, current_coverage)\n",
    "        \n",
    "        # Generate a subset covered by this rule\n",
    "        if true_false is None:\n",
    "            covered_subset = current_subset[current_subset[best_col] == best_val]\n",
    "        else:\n",
    "            if true_false == True:\n",
    "                covered_subset = current_subset[current_subset[best_col] >= best_val]\n",
    "            else:\n",
    "                covered_subset = current_subset[current_subset[best_col] < best_val]\n",
    "    \n",
    "    # If we did not refine the rule - return original rule and the original covered set\n",
    "    return (current_rule, covered_subset, best_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the main algorithm `learn_rules` takes as parameters list of columns, with the last column representing the class label, and the original data in form of pandas dataframe. Optionally, you can pass the list of classes in order that you are interested to explore first. Two optional threshold parameters `min_coverage` and `min_accuracy` set up the conditions of rule's validity for a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def learn_rules (columns, data, classes=None, \n",
    "                 min_coverage = 30, min_accuracy = 0.6):\n",
    "    # List of final rules\n",
    "    rules = []\n",
    "    \n",
    "    # If list of classes of interest is not provided - it is extracted from the last column of data\n",
    "    if classes is not None:\n",
    "        class_labels = classes\n",
    "    else:\n",
    "        class_labels = data[columns[-1]].unique().tolist()\n",
    "\n",
    "    current_data = data.copy()\n",
    "    \n",
    "    # This follows the logic of the original PRISM algorithm\n",
    "    # It processes each class in turn. Because for high accuracy \n",
    "    # the rules generated are disjoint with respect to class label\n",
    "    # this is not a problem when we are just interested in rules themselves - not classification\n",
    "    # For classification the order in which the rules are discovered matters, and we should \n",
    "    # process all the classes at the same time\n",
    "    for class_label in class_labels:\n",
    "        done = False\n",
    "        while len(current_data) > min_coverage and not done:\n",
    "            # Learn a rule with a single condition\n",
    "            \n",
    "            # If the best rule does not pass the coverage threshold - we are done with this class\n",
    "            if rule is None:\n",
    "                break\n",
    "\n",
    "            # If we get the rule with coverage above threshold\n",
    "            # We try to refine this rule\n",
    "            if rule is not None:\n",
    "                # try to improve the rule using the same learn_one_rule and passing existing rule as parameter\n",
    "                # here need another loop which stops when accuracy is not improving    \n",
    "                 \n",
    "                # done with this rule\n",
    "                if rule.accuracy >= min_accuracy:\n",
    "                    rules.append(rule)\n",
    "\n",
    "                    # remove rows covered by this rule\n",
    "                    # you have to remove the rows where all of the conditions hold\n",
    "                   \n",
    "                else:\n",
    "                    done = True\n",
    "            else:\n",
    "                done = True\n",
    "                \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correctness test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your algorithm on the original dataset from the PRISM paper.\n",
    "\n",
    "The dataset was downloaded from [here](https://archive.ics.uci.edu/ml/datasets/Lenses). The CSV version is included in this repository.\n",
    "\n",
    "**Attribute Information**:\n",
    "3 Classes:\n",
    "- __1__ : the patient should be fitted with __hard__ contact lenses,\n",
    "- __2__ : the patient should be fitted with __soft__ contact lenses,\n",
    "- __3__ : the patient should __not__ be fitted with contact lenses.\n",
    "\n",
    "Features:\n",
    "1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic\n",
    "2. spectacle prescription:  (1) myope, (2) hypermetrope\n",
    "3. astigmatic:     (1) no, (2) yes\n",
    "4. tear production rate:  (1) reduced, (2) normal\n",
    "\n",
    "Presbyopia is physiological insufficiency of accommodation associated with the aging of the eye that results in progressively worsening ability to focus clearly on close objects. So presbiopic means old.\n",
    "\n",
    "Hypermetropia: far-sightedness, also known as long-sightedness - cannot see close.\n",
    "Myopia: nearsightedness - cannot see at distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_file = \"contact_lenses.csv\"\n",
    "data = pd.read_csv(data_file, index_col=['id'])\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace numbers with actual values - for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes\n",
    "conditions = [ data['lenses type'].eq(1), data['lenses type'].eq(2), data['lenses type'].eq(3)]\n",
    "choices = [\"hard\",\"soft\",\"none\"]\n",
    "\n",
    "data['lenses type'] = np.select(conditions, choices)\n",
    "\n",
    "# age groups\n",
    "conditions = [ data['age'].eq(1), data['age'].eq(2), data['age'].eq(3)]\n",
    "choices = [\"young\",\"medium\",\"old\"]\n",
    "\n",
    "data['age'] = np.select(conditions, choices)\n",
    "\n",
    "# spectacles\n",
    "conditions = [ data['spectacles'].eq(1), data['spectacles'].eq(2)]\n",
    "choices = [\"nearsighted\",\"farsighted\"]\n",
    "\n",
    "data['spectacles'] = np.select(conditions, choices)\n",
    "\n",
    "# astigmatism\n",
    "conditions = [ data['astigmatism'].eq(1), data['astigmatism'].eq(2)]\n",
    "choices = [\"no\",\"yes\"]\n",
    "\n",
    "data['astigmatism'] = np.select(conditions, choices)\n",
    "\n",
    "# tear production rate\n",
    "conditions = [ data['tear production rate'].eq(1), data['tear production rate'].eq(2)]\n",
    "choices = [\"reduced\",\"normal\"]\n",
    "\n",
    "data['tear production rate'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = data.columns.to_numpy().tolist()\n",
    "rules = learn_rules (column_list, data, None, 1, 0.95)\n",
    "for rule in rules[:20]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My results are given below for comparison:\n",
    "\n",
    "If [tear production rate=reduced] then none. Coverage:12, accuracy: 1.0\n",
    "\n",
    "If [astigmatism=no, spectacles=farsighted] then soft. Coverage:3, accuracy: 1.0\n",
    "\n",
    "If [astigmatism=no, age=young] then soft. Coverage:1, accuracy: 1.0\n",
    "\n",
    "If [astigmatism=no, age=medium] then soft. Coverage:1, accuracy: 1.0\n",
    "\n",
    "If [age=young] then hard. Coverage:2, accuracy: 1.0\n",
    "\n",
    "If [spectacles=nearsighted, astigmatism=yes] then hard. Coverage:2, accuracy: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2020 Marina Barsky. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
